% Section: Gaussian Process Regression
\section{Gaussian Process Regression} \label{sec:intro}

\subsection{Regression}

\para{Regression}
Regression is probably one of the most fundamental problems in a wide range of fields including \emph{Statistics}, \emph{Signal Processing} and \emph{Machine Learning}, etc. A regression problem is usually formulated as follows:
Given a training set $D = \{ (\textbf{x}_{i}, y_{i}) | i = 1,2,...,n \}$, we assume that $\textbf{x}_{i}, y_{i}$ have the following relationship:
	\begin{equation}
		y_{i} = f(\textbf{x}_{i}) + e
	\end{equation}
where $e$ is the error noise. By finding such $f(\cdot)$, we can predict what a corresponding $y^{*}$ is in some test case $\textbf{x}^{*}$. Note that $\textbf{x}$ can either be a vector or a scalar.

\para{Generalized Linear Model}
A widely used regression model is called Generalized Linear Model(GLM)\cite{mccullagh1984generalized}, in which a regression function can be expressed as a linear combination:
	\begin{equation}
		f(\textbf{x}) = \sum_{i=1}^{M} w_{i}\phi_i (\textbf{x})
	\end{equation}
where $\phi_{i}(x)$ is called the basis function.
In a regular GLM analysis, we have to firstly determine what our basis functions we are going to use, and subsequently can we use the training dataset to derive the parameters in the basis functions and the coefficients in the regression function.
	
\para{Mean Square Error}
We use a measurement called the Mean Square Error(MSE) to evaluate the performance of the regression function. It is defined as follows:
	\begin{equation}
		MSE = \frac{1}{m}\sum^{m}_{i=1} (f(\textbf{x}^{*})-y_{i}^{*})^{2}
	\end{equation}
where $f(x)$ represents the regression function. A smaller MSE represents a better regression function on a test set.


\subsection{Gaussian Process Regression}

\para{Gaussian Process}
A Gaussian Process(GP) is any distribution over functions such that any finite set of function values $f(x_1), f(x_2), ..., f(x_N)$ have a joint Gaussian distribution\cite{rasmussen2006gaussian}. It can usually be represented as
\begin{equation}
N\{ E[ f(x) ], Cov[f(x), f(x^{'})] \}
\end{equation}
where $E[ f(x) ]$ refers to its \emph{Mean Function}, and $Cov[f(x), f(x^{'})]$ refers to its \emph{Covariance Function}.

\para{Gaussian Process Regression}
Gauss Process Regression(GPR)\cite{rasmussen2006gaussian} is a popular regression method these years.
The key of this method is to model the regression function $\{ f(\textbf{x}) | \textbf{x} \in S\}$ as a GP 
\begin{equation}
f(x) \gets N \{ m(\textbf{x}), K (\textbf{x},\textbf{x}^{'}) \}
\end{equation}
where $m(\textbf{x})$ is the \emph{Mean function} and $K (\textbf{x},\textbf{x}^{'})$ is the \emph{Kernel Function}.

In a GPR, we don't have to derive the exact form of the regression function, we just need to determine the form of the above two functions. 
As introduced in GP, the \emph{Kernel Function} $K (\textbf{x},\textbf{x}^{'})$ is actually the covariance between $f(\textbf{x})$ and $f(\textbf{x}^{'})$, and if it is a zero-mean GP, the covariance turns into correlation. So a \emph{Kernel Function} represents the relationship between $f(\textbf{x})$ and $f(\textbf{x}^{'})$.

By calculating the posterior probability of the desired $f(\textbf{x}^{*})$, \emph{i.e.} $p(f(\textbf{x}^{*}) | \textbf{x}^{*}, D)$, we can derive the mean value along with the standard deviation of this estimation. 
On the other hand, we must noted that calculating the posterior probability will become an intractable work when we have a high-dimensional dataset. It is a need that we introduce some inference method to estimate this work. \\

To summarize, choosing a suitable \emph{Mean Functions}, \emph{Kernel Functions} as well as the \emph{Likelihood Functions} and the \emph{Inference Methods} is the key of a GPR model.
Rasmussen's \emph{Gaussian Processes for Machine Learning}\cite{rasmussen2006gaussian} has implemented some marvellous Matlab/Octave code of GPR, it is available on his website\footnote{Available at \color{blue}\href{http://www.gaussianprocess.org/gpml/code/matlab/doc/}{http://www.gaussianprocess.org/gpml/code/}} known as \textbf{\emph{GPML}}.


